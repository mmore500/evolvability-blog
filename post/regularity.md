Regularity
==========

Definition
----------

Informally, regularity can be used to describe repetition phenotypic form.
Repetitive form might manifest as symmetry and/or recurring modular substructures.
Formally, regularity refers to how much information is required to describe a structure [[Clune et al., 2011]](#Clune2011OnRegularity).

Relation to Evolvability
------------------------

A bias towards regularity in phenotypic form tends to represent a bias towards viable variation.
That is, in many situations, regular phenotypes tend to outperform highly irregular phenotypes.
This conclusion that regular phenotypes tend to be more viable, of course, depends on the demands of the environment that the phenotype inhabits.
Phenotypic regularity tends to be useful in more regular environments (that is, environments that exhibit regular characteristics) [[Clune et al., 2011]](#Clune2011OnRegularity).
Many problem domains of interest to EANN researchers are highly regular [[Clune et al., 2011]](#Clune2011OnRegularity).
The natural world, the realm of flesh-and-blood creatures, also exhibits significant regularity [[Downing, 2015, p 16|]](#Downing2015IntelligenceSystems).
Encodings biased towards regularity can also be thought of as promoting structures that were not directly selected for during evolution.
These incidental phenotypic structures are called “spandrels,” referencing an architectural phenomenon that arises in a similarly unplanned for way: the awkward space between a curved archway set in a rectangular wall.
These regular structures might be more likely to perform well in fitness cases that were not tested.
It has been found that a tendency for regularity in evolving artificial neural networks produces networks that are capable of more generalized learning.
That is, EANN that are more likely to successfully perform tasks beyond those they were explicitly tested on during evolution [[Tonelli and Mouret, 2011]](#Tonelli2013OnNetworks).
Viewing learning as post-developmental (plastic) irregular refinement of regular neural structures created by development, a connection between regularity, irregular refinement (or plastic complexification), and plasticity is apparent in promoting phenotypic fitness.
In these ways, bias towards regularity increases evolvability because a higher proportion of individuals are viable.

Example
-------

*Aloe polyphylla*, which is known for the striking spiral arrangement of its leaves (Figure `aloe`), exemplifies regularity in nature [[Royal Horticultural Society, ]](#RoyalHorticulturalSocietyAloePolyphylla).
The phenotypic regularity exhibited by *Aloe polyphylla* is an important adaptation.
Phyllotaxis, the regular arrangement of leaves in plants, by minimizing the conflict between leaves for light, promotes efficient photosynthesis [[Kappraff, 2004]](#Kappraff2004GrowthNumber).

![image](http://devosoft.org/wp-content/uploads/2017/08/aloe.png)

References
----------

<a name="Clune2011OnRegularity">
Clune, J., Stanley, K. O., Pennock, R. T., and Ofria, C. (2011). On the performance of
indirect encoding across the continuum of regularity. IEEE Transactions on Evolutionary Computation.
</a>

<a name="Downing2015IntelligenceSystems">
Downing, K. L. (2015). Intelligence emerging : adaptivity and search in evolving neural
systems. MIT Press, Palatino.
</a>

<a name="Kappraff2004GrowthNumber">
Kappraff, J. (2004). Growth in Plants: A Study in Number. Form, 19:335–354.
</a>

<a name="RoyalHorticulturalSocietyAloePolyphylla">
Royal Horticultural Society. Aloe polyphylla.
</a>

<a name="Tonelli2013OnNetworks">
Tonelli, P. and Mouret, J. B. (2013). On the relationships between generative
encodings, regularity, and learning abilities when evolving plastic artificial neural networks. PLoS ONE.
</a>
